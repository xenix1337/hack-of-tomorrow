# Fetch AI Multi Agent System with Narrator Overseer

This module provides a FastAPI-based service for managing agents, setting their initial contexts, and sending messages to them. It supports asynchronous communication with multiple agents and ensures efficient handling of requests. The service also includes a narrator that oversees the conversation, providing context to the agents and choosing the best responses that enrich the conversation with the player.

## Features

- Allows setting an initial context for each agent using the /init endpoint.
The initial context is stored and used to prepend messages generated by the agent.
Send Messages:

- Sends messages to multiple agents concurrently using the /send-message endpoint.
Combines the initial context with the message before sending it to the agent.

- LLM based responses using FetchAI's ASI1-mini model.

- Narrator overseeing the conversation, providing context to the agents and choosing the best responses that provide the most value to the story and make the the experience deeply personal and engaging.

## Quickstart

Before running the service, install the required dependencies by running the following command:

```bash
pip install -r requirements.txt
```

then setup .env file with the following variables:

```bash
LLM_API_TOKEN=put_your_llm_token_here
LLM_URL=https://api.asi1.ai/v1/chat/completions
LLM_MODEL=asi1-mini
```

You can get the LLM_API_TOKEN by signing up at [ASI1](https://asi1.ai/)  
Example .env file is provided in the .env.example file.

To start the service, run the following command:

```bash
python agents.py
```

and in a separate terminal, run the following command:

```bash
python narrator.py
```
